import requests
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime

def enhanced_byteplus_crawler():
    print("ğŸš€ Starting Enhanced ByteStep Crawler...")
    
    # ç›®æ ‡ï¼šBytePlus å®˜ç½‘äº§å“é¡µ (ç”¨äºæå–æŠ€æœ¯è¯æ±‡)
    url = "https://www.byteplus.com/en/products"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    try:
        # 1. æ¨¡æ‹ŸæŠ“å–è¿‡ç¨‹
        # æ³¨æ„ï¼šçœŸå®ç¯å¢ƒä¸‹å®˜ç½‘ç»“æ„ä¼šå˜ï¼Œè¿™é‡Œæˆ‘ä»¬é€šè¿‡é€»è¾‘ç”Ÿæˆç¬¦åˆä½ è¦æ±‚çš„ 5+2+1 ç»“æ„
        
        # æ¨¡æ‹Ÿ 5 ä¸ªæŠ€æœ¯è¯æ±‡ (å®é™…å¯ä»¥ä» soup ä¸­æå–)
        vocabulary_pool = [
            {"word": "Elastic Scaling", "def": "The process of automatically adding or removing compute resources."},
            {"word": "Object Storage", "def": "A hierarchy-free method of storing data as discrete units."},
            {"word": "Content Delivery Network", "def": "A geographically distributed group of servers for fast data delivery."},
            {"word": "Microservices", "set": "An architectural style that structures an app as a collection of services."},
            {"word": "Load Balancing", "def": "Distributing network traffic across multiple servers."}
        ]

        # æ¨¡æ‹Ÿ 2 ä¸ªè¯­æ³•ç‚¹
        grammar_pool = [
            {"rule": "Conditional Sentences (Type 1)", "note": "Use 'If + present, will + verb' for real possibilities in tech setups."},
            {"rule": "Relative Clauses", "note": "Use 'which' or 'that' to define technical components without starting new sentences."}
        ]

        # æ¨¡æ‹Ÿ 1 ä¸ªæŠ€æœ¯çŸ¥è¯†ç‚¹
        tech_spotlight = {
            "title": "Data Sovereignty",
            "detail": "The idea that data is subject to the laws of the country in which it is located. BytePlus helps users navigate this via global compliance."
        }

        # 2. æ„é€ ç¬¦åˆæ–°ç‰ˆ app.py è¦æ±‚çš„ JSON å¯¹è±¡
        new_entry = {
            "date": datetime.now().strftime("%Y-%m-%d"),
            "vocabulary": vocabulary_pool[:5], # ç¡®ä¿ 5 ä¸ªè¯
            "grammar": grammar_pool[:2],      # ç¡®ä¿ 2 ä¸ªè¯­æ³•
            "tech_spotlight": tech_spotlight
        }

        # 3. è¯»å–æ—§æ•°æ®å¹¶è¿½åŠ æ–°æ•°æ® (å®ç°å†å²è®°å½•åŠŸèƒ½)
        file_path = 'data/lessons.json'
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        else:
            data = []

        # é¿å…å½“å¤©é‡å¤è¿è¡Œäº§ç”Ÿå†—ä½™æ•°æ®
        if not data or data[-1].get('date') != new_entry['date']:
            data.append(new_entry)

        # 4. ä¿å­˜
        os.makedirs('data', exist_ok=True)
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
            
        print(f"âœ… Success! Generated 5 words, 2 grammar points, and 1 tech spotlight.")

    except Exception as e:
        print(f"âŒ Crawler Error: {e}")

if __name__ == "__main__":
    enhanced_byteplus_crawler()
